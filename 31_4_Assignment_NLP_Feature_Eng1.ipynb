{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "31.4 Assignment NLP Feature Eng1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdQB1vtAIlGjUragrVZJlN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexBB999/NLP/blob/master/31_4_Assignment_NLP_Feature_Eng1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzIRN2RXTqz6",
        "colab_type": "text"
      },
      "source": [
        "##**Bag of words (BoW)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUFwJgy1T2LP",
        "colab_type": "text"
      },
      "source": [
        "Our first feature generation approach will be something called Bag of Words (BoW). \n",
        "\n",
        "BoW is quite simple: \n",
        "\n",
        "**our goal is to create a feature matrix such that the rows are observations and there is a column for each unique word in our vocabulary**.\n",
        "\n",
        " **Then we'll fill in this matrix by counting how many times each word appears in each observation**.\n",
        " \n",
        "  **We will then use those counts as features**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al9AZQzpUHqH",
        "colab_type": "text"
      },
      "source": [
        " In the jargon of scikit-learn, generating BoW features is called **CountVectorizer** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opyxH4sQTVsy",
        "colab_type": "code",
        "outputId": "d3ceaccb-a797-48ce-be96-5bfd9e4e3521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import spacy\n",
        "import re\n",
        "from nltk.corpus import gutenberg\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "!python -m spacy download en"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRZMhaTxUTgf",
        "colab_type": "text"
      },
      "source": [
        "Now, we write a **helper function called text_clearner** for cleaning the text.\n",
        "\n",
        " Specifically, we remove some punctuations and numbers from the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6WjAGJHUtQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utility function for standard text cleaning\n",
        "def text_cleaner(text):\n",
        "    # visual inspection identifies a form of punctuation spaCy does not\n",
        "    # recognize: the double dash '--'.  better get rid of it now!\n",
        "    text = re.sub(r'--',' ',text)\n",
        "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
        "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRShIiOvU4Qh",
        "colab_type": "text"
      },
      "source": [
        "**our unit of observation will be the sentences of these novels**\n",
        "\n",
        " or **in other terms**---->**our documents will be the sentences**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq5uhCvCTuJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load and clean the data\n",
        "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
        "alice = gutenberg.raw('carroll-alice.txt')\n",
        "\n",
        "# the Chapter indicator is idiosyncratic\n",
        "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
        "alice = re.sub(r'CHAPTER .*', '', alice)\n",
        "    \n",
        "alice = text_cleaner(alice)\n",
        "persuasion = text_cleaner(persuasion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD7-8BMCVdsj",
        "colab_type": "text"
      },
      "source": [
        "Our cleaned texts are stored in two variables called alice and persuasion.\n",
        "\n",
        " **Note that we didn't split the texts into sentences so far**.\n",
        " \n",
        "**We'll do that using SpaCy**.\n",
        "\n",
        " For that purpose, **we first load the English module of SpaCy and we parse both alice and persuasion texts with SpaCy**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9MhI1LeVvmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parse the cleaned novels. this can take a bit.\n",
        "nlp = spacy.load('en')\n",
        "alice_doc = nlp(alice)\n",
        "persuasion_doc = nlp(persuasion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5NoXN1XUKB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11f27fdf-92af-436b-90a4-df21ad3e12ad"
      },
      "source": [
        "alice_doc[0].is_alpha"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5ykDir8UOrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b9c0989-cbdd-4dc2-b3a4-31f298604d27"
      },
      "source": [
        "alice_doc[:10]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Alice was beginning to get very tired of sitting by"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PZJEZRxUVdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09cb4091-40eb-4b4a-e8e7-12356b6f9180"
      },
      "source": [
        "len(alice_doc)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34363"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSuaD1FXUinK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6df97c90-4b10-4c36-f6e6-58b9d258ded4"
      },
      "source": [
        "type(alice_doc)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voMhuBO-V7u_",
        "colab_type": "text"
      },
      "source": [
        "**We can split our texts into sentences now**.\n",
        "\n",
        " You can see how that is easy using SpaCy.\n",
        " \n",
        " Since previously we parsed our documents with SpaCy, we can now use SpaCy's functionalities.\n",
        " \n",
        "In this case, **SpaCy will take care of deriving the sentences from the texts**. \n",
        "  \n",
        "**What we need to do is to iterate over the parsed documents after calling the .sents attribute**\n",
        "\n",
        "In the following, **we iterate using the list comprehension**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiSHXcecWT4n",
        "colab_type": "code",
        "outputId": "9f25d735-d299-4f45-a20b-ee6ad6367774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# group into sentences\n",
        "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
        "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
        "\n",
        "# combine the sentences from the two novels into one data frame\n",
        "sentences = pd.DataFrame(alice_sents + persuasion_sents, columns = [\"text\", \"author\"])\n",
        "sentences.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   author\n",
              "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
              "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
              "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
              "3                                      (Oh, dear, !)  Carroll\n",
              "4                         (I, shall, be, late, !, ')  Carroll"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XguelTvX2qS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a9c2450-fdb3-477e-bed5-edb34cebc46f"
      },
      "source": [
        "len(sentences.loc[0][0])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RJm1euFYeXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "424790c9-c9b2-42a6-c991-4d0550a5e521"
      },
      "source": [
        "sentences.shape"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5848, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vphhabeNWjri",
        "colab_type": "text"
      },
      "source": [
        "**As a result, we ended up having a dataset that consists of two columns**.\n",
        "\n",
        "**In the first column, we have the sentences and in the second column**, **we have the authors**. \n",
        "\n",
        "**Before jumping in the BoW, we need to remove stopwords and punctuations**.\n",
        " \n",
        "**Then we should convert our tokens to lemmas or stems**.\n",
        "\n",
        "**In this example, we prefer to lemmatize our tokens**.\n",
        " \n",
        "  Again, we'll make use of the attributes of the parsed documents by SpaCy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-Eor0rTZ29Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get rid off stop words and punctuation\n",
        "# and lemmatize the tokens\n",
        "for i, sentence in enumerate(sentences[\"text\"]):\n",
        "    #print(len(sentence))\n",
        "    sentences.loc[i, \"text\"] = \" \".join(        [token.lemma_ for token in sentence if not token.is_stop and not token.is_punct])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrfXL5LGddc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "6cba234f-2d68-4997-deb2-ef9199ba90d6"
      },
      "source": [
        "sentences.head()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shall late</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   author\n",
              "0  Alice begin tired sit sister bank have twice p...  Carroll\n",
              "1  consider mind hot day feel sleepy stupid pleas...  Carroll\n",
              "2     remarkable Alice think way hear Rabbit oh dear  Carroll\n",
              "3                                            oh dear  Carroll\n",
              "4                                         shall late  Carroll"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn5lq4eZdsiz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "624c9621-e4ad-46ee-ce88-1f5686621d95"
      },
      "source": [
        "list(sentences)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text', 'author']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMvmPxebbFgf",
        "colab_type": "text"
      },
      "source": [
        "**Now we can start on converting the text in the first column of our dataset into a numerical form**.\n",
        "\n",
        "As we said before, we'll use BoW approach. For this purpose, we'll use **CountVectorizer** from scikit-learn as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdoN9xBDZ2L6",
        "colab_type": "text"
      },
      "source": [
        "**ADD SENTENCE LENGTH AS A FEATURE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYcog51edFPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#[len(sentence) for sentence in sentences['text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0cJK84MaLda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_length=pd.Series([len(sentence) for sentence in sentences['text']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd_07OW9bLJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer='word')\n",
        "X = vectorizer.fit_transform(sentences[\"text\"])\n",
        "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
        "bow_df[len]=sentence_length\n",
        "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48_u-J-72lRg",
        "colab_type": "code",
        "outputId": "7dd6f796-1666-4c11-a61f-0d6db933f120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "bow_df"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1st</th>\n",
              "      <th>29th</th>\n",
              "      <th>abbreviation</th>\n",
              "      <th>abdication</th>\n",
              "      <th>abide</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>abode</th>\n",
              "      <th>abominable</th>\n",
              "      <th>abominate</th>\n",
              "      <th>abroad</th>\n",
              "      <th>absence</th>\n",
              "      <th>absent</th>\n",
              "      <th>absolute</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>abstraction</th>\n",
              "      <th>absurd</th>\n",
              "      <th>absurdity</th>\n",
              "      <th>abundance</th>\n",
              "      <th>abuse</th>\n",
              "      <th>abydos</th>\n",
              "      <th>accent</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>acceptance</th>\n",
              "      <th>accession</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidental</th>\n",
              "      <th>accidentally</th>\n",
              "      <th>accommodate</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>accompany</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>accomplished</th>\n",
              "      <th>accomplishment</th>\n",
              "      <th>accord</th>\n",
              "      <th>accordingly</th>\n",
              "      <th>accost</th>\n",
              "      <th>account</th>\n",
              "      <th>accounting</th>\n",
              "      <th>...</th>\n",
              "      <th>wrap</th>\n",
              "      <th>wrapt</th>\n",
              "      <th>wreck</th>\n",
              "      <th>wretched</th>\n",
              "      <th>wretchedly</th>\n",
              "      <th>wretchedness</th>\n",
              "      <th>wriggle</th>\n",
              "      <th>wrinkle</th>\n",
              "      <th>wrist</th>\n",
              "      <th>write</th>\n",
              "      <th>writhing</th>\n",
              "      <th>writing</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrought</th>\n",
              "      <th>yard</th>\n",
              "      <th>yarmouth</th>\n",
              "      <th>yawn</th>\n",
              "      <th>ye</th>\n",
              "      <th>year</th>\n",
              "      <th>yearly</th>\n",
              "      <th>yell</th>\n",
              "      <th>yelp</th>\n",
              "      <th>yeoman</th>\n",
              "      <th>yer</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yestermorn</th>\n",
              "      <th>yield</th>\n",
              "      <th>yielding</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>younker</th>\n",
              "      <th>youth</th>\n",
              "      <th>youthful</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealous</th>\n",
              "      <th>zealously</th>\n",
              "      <th>zigzag</th>\n",
              "      <th>5848</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5843</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5844</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5845</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5846</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5847</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5848 rows × 4866 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      1st  29th  abbreviation  abdication  ...  zealous  zealously  zigzag  5848\n",
              "0       0     0             0           0  ...        0          0       0   129\n",
              "1       0     0             0           0  ...        0          0       0   136\n",
              "2       0     0             0           0  ...        0          0       0    46\n",
              "3       0     0             0           0  ...        0          0       0     7\n",
              "4       0     0             0           0  ...        0          0       0    10\n",
              "...   ...   ...           ...         ...  ...      ...        ...     ...   ...\n",
              "5843    0     0             0           0  ...        0          0       0    52\n",
              "5844    0     0             0           0  ...        0          0       0    49\n",
              "5845    0     0             0           0  ...        0          0       0    63\n",
              "5846    0     0             0           0  ...        0          0       0   114\n",
              "5847    0     0             0           0  ...        0          0       0     5\n",
              "\n",
              "[5848 rows x 4866 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpBDrHRXbTBW",
        "colab_type": "code",
        "outputId": "4bbe7001-b251-4182-ed84-7c74be432f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bow_df.shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5848, 4866)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBlBDYgQbiYb",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we have a dataset that we're familiar from the rest of the bootcamp.\n",
        "\n",
        "It's in tabular form:\n",
        "\n",
        " **observations sit on rows** and **we have our features as columns**.\n",
        " \n",
        "More importantly, we converted text into a numerical form so that we can apply machine learning algorithms using these as input.\n",
        "  \n",
        "  **This enables us to move to the modeling phase** as demonstrated below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QqEps-GbzW-",
        "colab_type": "text"
      },
      "source": [
        "##**BoW in action**\n",
        "\n",
        "Now let's give the bag of words features a whirl by trying some **machine learning algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJu9Uo3nb4wq",
        "colab_type": "code",
        "outputId": "b44dec9f-d2d1-4327-c4b7-cd9d885e797e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y = sentences['author']\n",
        "X = np.array(sentences.drop(['text','author'], 1))\n",
        "\n",
        "# We split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
        "\n",
        "# Models\n",
        "lr = LogisticRegression()\n",
        "rfc = RandomForestClassifier()\n",
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "rfc.fit(X_train, y_train)\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Random Forest Scores----------------------\")\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
        "print('Training set score:', gbc.score(X_train, y_train))\n",
        "print('\\nTest set score:', gbc.score(X_test, y_test))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.9424173318129989\n",
            "\n",
            "Test set score: 0.8636752136752137\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.9732041049030786\n",
            "\n",
            "Test set score: 0.8581196581196581\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.8443557582668187\n",
            "\n",
            "Test set score: 0.8235042735042735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzsffTc1cbJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "----------------------Logistic Regression Scores----------------------\n",
        "Training set score: 0.9261687571265679\n",
        "\n",
        "Test set score: 0.8641025641025641\n",
        "----------------------Random Forest Scores----------------------\n",
        "Training set score: 0.9723489167616876\n",
        "\n",
        "Test set score: 0.832905982905983\n",
        "----------------------Gradient Boosting Scores----------------------\n",
        "Training set score: 0.8275370581527937\n",
        "\n",
        "Test set score: 0.8128205128205128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8BbRoGackR4",
        "colab_type": "text"
      },
      "source": [
        "**It looks like logistic regression and random forest overfit.**\n",
        "\n",
        " **Overfitting is a known problem when using bag of words**, \n",
        "\n",
        " **since it involves throwing a massive number of features at a model** – \n",
        " \n",
        "**some of those features** (in this case, word frequencies) **will capture noise in the training set**.\n",
        " \n",
        "Since overfitting is also a known problem with Random Forests, the divergence between training score and test score is expected. On the other hand, gradient boosting's training and test scores are close to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsW2a51bc66V",
        "colab_type": "text"
      },
      "source": [
        "**//////////////////////////////////////////////////////////////**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd6hRPo4dunH",
        "colab_type": "text"
      },
      "source": [
        "#**N-grams: words in context**\n",
        "\n",
        "Consider the word ‘vain’ in these two sentences:\n",
        "\n",
        "“She labored in vain, the rock would not move.” \n",
        "\n",
        "“She was so vain, her bathroom mirror was covered in lip prints.”\n",
        "In both sentences, ‘vain’ is an adjective. In sentence 1, it signals a lack of success. In sentence 2, the same word means vanity.\n",
        "\n",
        "**Since the two usages can’t be distinguished by their part of speech, how can we tell them apart?**\n",
        "\n",
        "**N-grams incorporate context information by creating features made up of a series of consecutive words**.\n",
        "\n",
        "The ‘N’ refers to the number of words included in the series. For example, the 2-gram representation of sentence 1 would be:\n",
        "\n",
        "(She labored), (labored in), (in vain), (vain the), (the rock), (rock would), (would not), (not move).\n",
        "The 3-gram representation of sentence 2 would be:\n",
        "\n",
        "(She was so), (was so vain), (so vain her), (vain her bathroom), (her bathroom mirror), (bathroom mirror was), (mirror was covered), (was covered in), (covered in lip), (in lip prints).\n",
        "\n",
        "**Each of the word sets can then operate as its own feature**.\n",
        "\n",
        "**N-grams can be used to create term-document matrices** (though it would now be ngram-document matrices), or used in topic modeling.\n",
        "\n",
        "In addition, **n-grams are useful for text prediction **\n",
        "\n",
        "**as they can be used to determine what words are most likely to follow in a sentence, phrase, or search query**.\n",
        "\n",
        "**For a sentence with X words, there will be  𝑋−(𝑁−1)  n-grams**. 2-gram phrases are also called ‘bigrams,’ 3-gram phrases are called ‘trigrams,’ etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-nvUZo1eJd3",
        "colab_type": "text"
      },
      "source": [
        "##**Why use words alone**\n",
        "\n",
        "Given the benefits of incorporating word context for distinguishing between different meanings of a word, **why would any NLP practitioner worth their salt ever use simple word features**?\n",
        "\n",
        "**Because models based on single words have several advantages**:\n",
        "\n",
        "First, n-gram models are considerably more sparse than single-word models.\n",
        "\n",
        " The two ‘vain’ sentences above share four words (‘she’, ‘in’, ‘vain’, ‘the’) but zero n-grams. Sparseness does mean that an n-gram model can be stored in a more memory-efficient way (for example, in a dict that only lists the n-grams that are present in each sentence rather than a set of columns with 1 if an n-gram is present and 0 otherwise). However, it also means that a larger corpus may be needed to detect any shared patterns across documents.\n",
        " \n",
        " **In other words, n-gram models may need more documents before they start to give good results**.\n",
        "\n",
        "**Second, single-word models are straightforward to implement**,\n",
        "\n",
        "**while models incorporating n-grams are more sensitive to fine distinctions of meaning.**\n",
        "\n",
        " **Which to choose depends on the goals of the NLP project and the trade-offs in ** **bold text**time** and performance for the specific corpus we are modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe8tZdcefbIS",
        "colab_type": "text"
      },
      "source": [
        "**2-gram example**\n",
        "\n",
        "Implementing n-grams is quite easy using scikit-learn's CountVectorizer.\n",
        "\n",
        "**The only thing we should do is to give a tuple of range as values to a parameter of CountVectorizer which is called ngram_range**.\n",
        "\n",
        " As the code below demonstrates, we provide a value for the parameter ngram_range=(2,2) inside CountVectorizer. \n",
        " \n",
        " This means that the vectorizer will produce 2-gram features. If we were to give ngram_range=(1,2) as value, then the vectorizer would produce both 1-gram and 2-gram together. However, we keep it as an assignment for you.\n",
        "\n",
        "Let's generate our 2-grams and see what it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ5mpRnnf8N6",
        "colab_type": "code",
        "outputId": "ac13c224-93c9-4efb-e3e7-474d1dd15e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "# we'll use 2-grams\n",
        "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2,2))\n",
        "X = vectorizer.fit_transform(sentences[\"text\"])\n",
        "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
        "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)\n",
        "sentences.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>29th september</th>\n",
              "      <th>abbreviation living</th>\n",
              "      <th>abdication neighbour</th>\n",
              "      <th>abide consequence</th>\n",
              "      <th>abide figure</th>\n",
              "      <th>ability affection</th>\n",
              "      <th>ability awkwardness</th>\n",
              "      <th>ability difficulty</th>\n",
              "      <th>able attempt</th>\n",
              "      <th>able avail</th>\n",
              "      <th>able avoid</th>\n",
              "      <th>able bear</th>\n",
              "      <th>able convince</th>\n",
              "      <th>able devise</th>\n",
              "      <th>able eat</th>\n",
              "      <th>able far</th>\n",
              "      <th>able feign</th>\n",
              "      <th>able join</th>\n",
              "      <th>able judge</th>\n",
              "      <th>able leave</th>\n",
              "      <th>able letter</th>\n",
              "      <th>able live</th>\n",
              "      <th>able marry</th>\n",
              "      <th>able persuade</th>\n",
              "      <th>able regard</th>\n",
              "      <th>able remain</th>\n",
              "      <th>able return</th>\n",
              "      <th>able ring</th>\n",
              "      <th>able rise</th>\n",
              "      <th>able set</th>\n",
              "      <th>able shew</th>\n",
              "      <th>able speak</th>\n",
              "      <th>able tell</th>\n",
              "      <th>able trace</th>\n",
              "      <th>able turn</th>\n",
              "      <th>able watch</th>\n",
              "      <th>abominable promise</th>\n",
              "      <th>abominate young</th>\n",
              "      <th>abroad intention</th>\n",
              "      <th>abroad supposition</th>\n",
              "      <th>...</th>\n",
              "      <th>young old</th>\n",
              "      <th>young parson</th>\n",
              "      <th>young people</th>\n",
              "      <th>young person</th>\n",
              "      <th>young sister</th>\n",
              "      <th>young squire</th>\n",
              "      <th>young thoughtless</th>\n",
              "      <th>young woman</th>\n",
              "      <th>young young</th>\n",
              "      <th>youth beauty</th>\n",
              "      <th>youth bloom</th>\n",
              "      <th>youth early</th>\n",
              "      <th>youth father</th>\n",
              "      <th>youth fine</th>\n",
              "      <th>youth hardly</th>\n",
              "      <th>youth hope</th>\n",
              "      <th>youth jaw</th>\n",
              "      <th>youth kill</th>\n",
              "      <th>youth learn</th>\n",
              "      <th>youth like</th>\n",
              "      <th>youth mention</th>\n",
              "      <th>youth possibly</th>\n",
              "      <th>youth restore</th>\n",
              "      <th>youth say</th>\n",
              "      <th>youth spring</th>\n",
              "      <th>youth value</th>\n",
              "      <th>youth vigour</th>\n",
              "      <th>youthful infatuation</th>\n",
              "      <th>zeal business</th>\n",
              "      <th>zeal common</th>\n",
              "      <th>zeal dwell</th>\n",
              "      <th>zeal sport</th>\n",
              "      <th>zeal think</th>\n",
              "      <th>zealand australia</th>\n",
              "      <th>zealous officer</th>\n",
              "      <th>zealous subject</th>\n",
              "      <th>zealously discharge</th>\n",
              "      <th>zigzag go</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>shall late</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30448 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   29th september  ...   author\n",
              "0               0  ...  Carroll\n",
              "1               0  ...  Carroll\n",
              "2               0  ...  Carroll\n",
              "3               0  ...  Carroll\n",
              "4               0  ...  Carroll\n",
              "\n",
              "[5 rows x 30448 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o8mPgccgBtT",
        "colab_type": "text"
      },
      "source": [
        "**As you see, our new features are 2-gram**. \n",
        "\n",
        "Next, let's build the same machine learning models that we built before for the 1-gram case but this time using 2-gram as our features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg4EQd1kfvYI",
        "colab_type": "code",
        "outputId": "9cece639-0160-4170-f628-105777e2d941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "Y = sentences['author']\n",
        "X = np.array(sentences.drop(['text','author'], 1))\n",
        "\n",
        "# We split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
        "\n",
        "# Models\n",
        "lr = LogisticRegression()\n",
        "rfc = RandomForestClassifier()\n",
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "rfc.fit(X_train, y_train)\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Random Forest Scores----------------------\")\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
        "print('Training set score:', gbc.score(X_train, y_train))\n",
        "print('\\nTest set score:', gbc.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.895381984036488\n",
            "\n",
            "Test set score: 0.782051282051282\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.9304446978335233\n",
            "\n",
            "Test set score: 0.6188034188034188\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.7528506271379704\n",
            "\n",
            "Test set score: 0.7538461538461538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gktkgTBygLpH",
        "colab_type": "text"
      },
      "source": [
        "The results seem worse than 1-gram! Even overfitting in the logistic regression and the random forest is higher than before.\n",
        "\n",
        "**That's because in the 2-gram case, we have more number of features than we have in 1-gram**.\n",
        "\n",
        "**One possible solution to increase the performance of the models is using 1-gram and 2-gram together as features**. \n",
        "\n",
        "This will be one of your tasks in the assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y96yofbf3zJD",
        "colab_type": "text"
      },
      "source": [
        "#*ASSIGNMENTS**\n",
        "Your task is to increase the performance of the models we implemented in the BoW example. Suggested avenues of investigation include:\n",
        "\n",
        "Other modeling techniques and models\n",
        "\n",
        "Making more features that take advantage of the SpaCy information (include grammar, phrases, POS, etc)\n",
        "\n",
        "Making sentence-level features (number of words, amount of punctuation)\n",
        "\n",
        "Including contextual information (length of previous and next sentences, words repeated from one sentence to the next, etc)\n",
        "\n",
        "Or anything else your heart desires.\n",
        "\n",
        "Compare your models' performances with those of the example.\n",
        "\n",
        "In the 2-gram example above, we only used 2-gram as our features. This time, use both 1-gram and 2-gram features together as your feature set. Run the same models in the example and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZdY6c4H4OtM",
        "colab_type": "text"
      },
      "source": [
        "##**TRY SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0pRX_LrRGg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = sentences['author']\n",
        "X = np.array(sentences.drop(['text','author'], 1))\n",
        "\n",
        "# We split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yuc7xSc147ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hEGeS9k5PRu",
        "colab_type": "code",
        "outputId": "c657dc0f-0075-42f0-c17f-7b7371eaa9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"----------------------SVM Scores----------------------\")\n",
        "print('Training set score:', clf.score(X_train, y_train))\n",
        "print('\\nTest set score:', clf.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------SVM Scores----------------------\n",
            "Training set score: 0.9327251995438997\n",
            "\n",
            "Test set score: 0.8542735042735042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qn_O86g6Bx5",
        "colab_type": "text"
      },
      "source": [
        "SOME OVERFITTING\n",
        "\n",
        "**TRY RBF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZtzWrfF6M8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a svm Classifier\n",
        "rbf = svm.SVC(kernel='rbf') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "rbf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = rbf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzGSRKQp6_1x",
        "colab_type": "code",
        "outputId": "38149253-3052-4f26-e9c5-9b09b2346780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"----------------------RBF Scores----------------------\")\n",
        "print('Training set score:', rbf.score(X_train, y_train))\n",
        "print('\\nTest set score:', rbf.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------SVM Scores----------------------\n",
            "Training set score: 0.8993728620296465\n",
            "\n",
            "Test set score: 0.8277777777777777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hVnPYep7kiU",
        "colab_type": "text"
      },
      "source": [
        "**NOT ANY BETTER**\n",
        "\n",
        "TRY AGAIN WITH C=10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erhJI1-m9Z9q",
        "colab_type": "code",
        "outputId": "6753a50d-86d2-4cba-a06f-6f58df7c34be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"----------------------RBF Scores----------------------\")\n",
        "print('Training set score:', rbf.score(X_train, y_train))\n",
        "print('\\nTest set score:', rbf.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------RBF Scores----------------------\n",
            "Training set score: 0.9689281641961232\n",
            "\n",
            "Test set score: 0.8196581196581196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IprASnsa92Xz",
        "colab_type": "text"
      },
      "source": [
        "MUCH WORSE\n",
        "**REGULARIZATION IS INVERSLY PROPORTIONAL TO C**\n",
        "\n",
        "TRY WITH C=.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EjcvICO-JKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a SVM Classifier\n",
        "from sklearn import svm\n",
        "rbf = svm.SVC(kernel='rbf',C=.1) # rbf KERNEL\n",
        "\n",
        "#Train the model using the training sets\n",
        "rbf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "\n",
        "y_pred = rbf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llf4H56i-9M6",
        "colab_type": "code",
        "outputId": "f93ed47e-1eaa-4a54-a287-26f369ff7c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"----------------------RBF Scores----------------------\")\n",
        "print('Training set score:', rbf.score(X_train, y_train))\n",
        "print('\\nTest set score:', rbf.score(X_test, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------RBF Scores----------------------\n",
            "Training set score: 0.7397377423033067\n",
            "\n",
            "Test set score: 0.7423076923076923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP_8ENmTBmqY",
        "colab_type": "text"
      },
      "source": [
        "**OVERFITTING FIXED**\n",
        "\n",
        "**SCORE IS MEDIOCRE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7d0qRhe5XsO",
        "colab_type": "text"
      },
      "source": [
        "**WILL ADD FEATURE(S)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AwzhQ1L5fTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import FeatureUnion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu9rhZZBfwId",
        "colab_type": "text"
      },
      "source": [
        "**THIS FEATURE HAS BEEN ALREADY BEEN ADDED -- SENTENCE LENGTH**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vet8eWNufjHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_length=pd.Series([len(sentence) for sentence in sentences['text']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gK1iah8gAIG",
        "colab_type": "text"
      },
      "source": [
        "**LET'S SEE IF IT IMPROVES RBF SCORE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CR4kPX0gF0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a svm Classifier\n",
        "rbf = svm.SVC(kernel='rbf') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "rbf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = rbf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKkHsZhTg2Sf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "777be267-0854-4071-a50a-57de29debea0"
      },
      "source": [
        "print(\"----------------------RBF Scores----------------------\")\n",
        "print('Training set score:', rbf.score(X_train, y_train))\n",
        "print('\\nTest set score:', rbf.score(X_test, y_test))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------RBF Scores----------------------\n",
            "Training set score: 0.6590649942987458\n",
            "\n",
            "Test set score: 0.6675213675213675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0sIhhFphpsM",
        "colab_type": "text"
      },
      "source": [
        "**MUCH WORSE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojQgXLwbiHaD",
        "colab_type": "text"
      },
      "source": [
        "**TRY WITH LINEAR KERNEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXRTFDmoiPnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBzgu01zi-gk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "2a7cdc14-be16-4554-90a9-2e607869488c"
      },
      "source": [
        "print(\"----------------------SVM Scores----------------------\")\n",
        "print('Training set score:', clf.score(X_train, y_train))\n",
        "print('\\nTest set score:', clf.score(X_test, y_test))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------SVM Scores----------------------\n",
            "Training set score: 0.9538198403648803\n",
            "\n",
            "Test set score: 0.8572649572649572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nKceZo9jkOE",
        "colab_type": "text"
      },
      "source": [
        "**ACCURACY IS UP -- STILL OVERFITTING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMngIDZ1lJB-",
        "colab_type": "text"
      },
      "source": [
        "**CHANGE C TO REDUCE OVERFITTING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDuwHD3tlUqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear',C=.5) # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95bAwV8pl31F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "0a07865c-b349-4fe4-eb30-5d9bae31c330"
      },
      "source": [
        "print(\"----------------------SVM Scores----------------------\")\n",
        "print('Training set score:', clf.score(X_train, y_train))\n",
        "print('\\nTest set score:', clf.score(X_test, y_test))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------SVM Scores----------------------\n",
            "Training set score: 0.9293044469783353\n",
            "\n",
            "Test set score: 0.8542735042735042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVnhSgOQmOjJ",
        "colab_type": "text"
      },
      "source": [
        "**DID NOT HELP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrJkfX1wmSWR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**TRY C=2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZTY9LRnmbJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear',C=2) # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv109tSEmyBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "8fae16f8-19c4-40ad-ab32-6ffcfe4eb919"
      },
      "source": [
        "print(\"----------------------SVM Scores----------------------\")\n",
        "print('Training set score:', clf.score(X_train, y_train))\n",
        "print('\\nTest set score:', clf.score(X_test, y_test))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------SVM Scores----------------------\n",
            "Training set score: 0.9569555302166477\n",
            "\n",
            "Test set score: 0.8508547008547008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcadpd5jnDIH",
        "colab_type": "text"
      },
      "source": [
        "**UGH**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Sr8TbwuPsv",
        "colab_type": "text"
      },
      "source": [
        "##**N-GRAMS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk99N94Duj23",
        "colab_type": "text"
      },
      "source": [
        "WE'LL USE 1-GRAM AND 2-GRAM TOGETHER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul-8H92duWla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "f440c6c7-5e65-4baa-be7f-19497c743cd1"
      },
      "source": [
        "# we'll use 2-grams\n",
        "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2))\n",
        "X = vectorizer.fit_transform(sentences[\"text\"])\n",
        "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
        "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)\n",
        "sentences.head()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1st</th>\n",
              "      <th>29th</th>\n",
              "      <th>29th september</th>\n",
              "      <th>abbreviation</th>\n",
              "      <th>abbreviation living</th>\n",
              "      <th>abdication</th>\n",
              "      <th>abdication neighbour</th>\n",
              "      <th>abide</th>\n",
              "      <th>abide consequence</th>\n",
              "      <th>abide figure</th>\n",
              "      <th>ability</th>\n",
              "      <th>ability affection</th>\n",
              "      <th>ability awkwardness</th>\n",
              "      <th>ability difficulty</th>\n",
              "      <th>able</th>\n",
              "      <th>able attempt</th>\n",
              "      <th>able avail</th>\n",
              "      <th>able avoid</th>\n",
              "      <th>able bear</th>\n",
              "      <th>able convince</th>\n",
              "      <th>able devise</th>\n",
              "      <th>able eat</th>\n",
              "      <th>able far</th>\n",
              "      <th>able feign</th>\n",
              "      <th>able join</th>\n",
              "      <th>able judge</th>\n",
              "      <th>able leave</th>\n",
              "      <th>able letter</th>\n",
              "      <th>able live</th>\n",
              "      <th>able marry</th>\n",
              "      <th>able persuade</th>\n",
              "      <th>able regard</th>\n",
              "      <th>able remain</th>\n",
              "      <th>able return</th>\n",
              "      <th>able ring</th>\n",
              "      <th>able rise</th>\n",
              "      <th>able set</th>\n",
              "      <th>able shew</th>\n",
              "      <th>able speak</th>\n",
              "      <th>able tell</th>\n",
              "      <th>...</th>\n",
              "      <th>young young</th>\n",
              "      <th>younker</th>\n",
              "      <th>youth</th>\n",
              "      <th>youth beauty</th>\n",
              "      <th>youth bloom</th>\n",
              "      <th>youth early</th>\n",
              "      <th>youth father</th>\n",
              "      <th>youth fine</th>\n",
              "      <th>youth hardly</th>\n",
              "      <th>youth hope</th>\n",
              "      <th>youth jaw</th>\n",
              "      <th>youth kill</th>\n",
              "      <th>youth learn</th>\n",
              "      <th>youth like</th>\n",
              "      <th>youth mention</th>\n",
              "      <th>youth possibly</th>\n",
              "      <th>youth restore</th>\n",
              "      <th>youth say</th>\n",
              "      <th>youth spring</th>\n",
              "      <th>youth value</th>\n",
              "      <th>youth vigour</th>\n",
              "      <th>youthful</th>\n",
              "      <th>youthful infatuation</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zeal business</th>\n",
              "      <th>zeal common</th>\n",
              "      <th>zeal dwell</th>\n",
              "      <th>zeal sport</th>\n",
              "      <th>zeal think</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealand australia</th>\n",
              "      <th>zealous</th>\n",
              "      <th>zealous officer</th>\n",
              "      <th>zealous subject</th>\n",
              "      <th>zealously</th>\n",
              "      <th>zealously discharge</th>\n",
              "      <th>zigzag</th>\n",
              "      <th>zigzag go</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>shall late</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35313 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1st  29th  ...                                               text   author\n",
              "0    0     0  ...  Alice begin tired sit sister bank have twice p...  Carroll\n",
              "1    0     0  ...  consider mind hot day feel sleepy stupid pleas...  Carroll\n",
              "2    0     0  ...     remarkable Alice think way hear Rabbit oh dear  Carroll\n",
              "3    0     0  ...                                            oh dear  Carroll\n",
              "4    0     0  ...                                         shall late  Carroll\n",
              "\n",
              "[5 rows x 35313 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrCRkm0TvQr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "084e1525-e5d0-4dba-c4b7-9202449cc770"
      },
      "source": [
        "Y = sentences['author']\n",
        "X = np.array(sentences.drop(['text','author'], 1))\n",
        "\n",
        "# We split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
        "\n",
        "# Models\n",
        "lr = LogisticRegression()\n",
        "rfc = RandomForestClassifier()\n",
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "rfc.fit(X_train, y_train)\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Random Forest Scores----------------------\")\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
        "print('Training set score:', gbc.score(X_train, y_train))\n",
        "print('\\nTest set score:', gbc.score(X_test, y_test))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.9444127708095781\n",
            "\n",
            "Test set score: 0.8662393162393163\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.9723489167616876\n",
            "\n",
            "Test set score: 0.8350427350427351\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.8292474344355758\n",
            "\n",
            "Test set score: 0.8158119658119658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tGl3wtzx8em",
        "colab_type": "text"
      },
      "source": [
        "**IMPROVEMENT OVER 2-GRAM ALONE**"
      ]
    }
  ]
}